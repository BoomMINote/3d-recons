{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2, os\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import warnings\n",
    "# from scipy.misc import toimage, imsave\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "import gc\n",
    "# from sklearn.utils import shuffle\n",
    "# from scipy.linalg import norm\n",
    "# from scipy import sum, average\n",
    "# from scipy.interpolate import RectBivariateSpline\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras, sys, time\n",
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NUM = 30600\n",
    "VAL_NUM = 5400\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128, 6)\n",
      "(None, 128, 128, 6)\n",
      "(None, 64, 64, 18)\n",
      "(None, 32, 32, 36)\n",
      "(None, 16, 16, 72)\n",
      "(None, 8, 8, 144)\n",
      "(None, 4, 4, 144)\n",
      "(None, 8, 8, 72)\n",
      "(None, 8, 8, 216)\n",
      "(None, 16, 16, 36)\n",
      "(None, 16, 16, 108)\n",
      "(None, 32, 32, 18)\n",
      "(None, 32, 32, 54)\n",
      "(None, 64, 64, 9)\n",
      "(None, 64, 64, 27)\n",
      "(None, 128, 128, 15)\n",
      "(None, 8, 8, 216)\n",
      "(None, 16, 16, 36)\n",
      "(None, 16, 16, 108)\n",
      "(None, 32, 32, 18)\n",
      "(None, 32, 32, 54)\n",
      "(None, 64, 64, 9)\n",
      "(None, 64, 64, 27)\n",
      "(None, 128, 128, 7)\n",
      "(None, 128, 128, 22)\n",
      "(None, 128, 128, 22)\n"
     ]
    }
   ],
   "source": [
    "def FluidNet( nClasses, nClasses1 , input_height=128, input_width=128):\n",
    "    assert input_height%32 == 0\n",
    "    assert input_width%32 == 0\n",
    "    IMAGE_ORDERING =  \"channels_last\" \n",
    "\n",
    "    img_input = Input(shape=(input_height,input_width, 6), name='combined_input') ## Assume 128,128,6\n",
    "    print(img_input.shape)\n",
    "    ## Block 1 128x128\n",
    "    x = Conv2D(18, (2, 2), activation='relu', padding='same', name='block1_conv1', data_format=IMAGE_ORDERING )(img_input)\n",
    "    x = Conv2D(18, (2, 2), activation='relu', padding='same', name='block1_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f1 = x\n",
    "    print(f1.shape)\n",
    "    \n",
    "    # Block 2 64x64\n",
    "    x = Conv2D(36, (2, 2), activation='relu', padding='same', name='block2_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(36, (2, 2), activation='relu', padding='same', name='block2_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f2 = x\n",
    "    print(f2.shape)\n",
    "\n",
    "    # Block 3 32x32\n",
    "    x = Conv2D(72, (2, 2), activation='relu', padding='same', name='block3_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(72, (2, 3), activation='relu', padding='same', name='block3_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(72, (2, 2), activation='relu', padding='same', name='block3_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    pool3 = x\n",
    "    print(pool3.shape)\n",
    "    \n",
    "    # Block 4 16x16\n",
    "    x = Conv2D(144, (2, 2), activation='relu', padding='same', name='block4_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(144, (2, 2), activation='relu', padding='same', name='block4_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(144, (2, 2), activation='relu', padding='same', name='block4_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    print(pool4.shape)\n",
    "    \n",
    "    # Block 5 8x8\n",
    "    x = Conv2D(144, (2, 2), activation='relu', padding='same', name='block5_conv1', data_format=IMAGE_ORDERING )(pool4)\n",
    "    x = Conv2D(144, (2, 2), activation='relu', padding='same', name='block5_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(144, (2, 2), activation='relu', padding='same', name='block5_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    pool5 = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    print(pool5.shape)\n",
    "    \n",
    "    # Block Transpose <DECODER> : Depth\n",
    "    #1st deconv layer 4x4\n",
    "    x = (Conv2DTranspose( 72, kernel_size=(4,4) ,  strides=(2,2) , padding='same', dilation_rate = (1,1), use_bias=False, data_format=IMAGE_ORDERING, name=\"Transpose_pool5\" ) (pool5))\n",
    "    print(x.shape)\n",
    "    #concatinate x and pool4 for 2nd Deconv layer 8X8\n",
    "    x = concatenate ([x, pool4],axis = 3)\n",
    "    print(x.shape)\n",
    "    x = (Conv2DTranspose( 36 , kernel_size=(6,6) ,  strides=(2,2) ,padding='same', dilation_rate = (1,1), use_bias=False, data_format=IMAGE_ORDERING, name=\"Transpose_pool4\")(x))\n",
    "    print(x.shape)\n",
    "    #concatinate x and pool3 for 3rd Deconv layer 28x28\n",
    "    x = concatenate ([x, pool3],axis = 3) \n",
    "    print(x.shape)   \n",
    "    x= (Conv2DTranspose( 18 , kernel_size=(4,4) ,  strides=(2,2) , padding='same',dilation_rate = (1,1), use_bias=False, data_format=IMAGE_ORDERING, name=\"Transpose_pool3\" )(x))\n",
    "    print(x.shape)\n",
    "    #concatinate x and f2 for 4th Deconv layer\n",
    "    x = concatenate ([x, f2],axis = 3)   \n",
    "    print(x.shape) \n",
    "    x = (Conv2DTranspose( 9 , kernel_size=(4,4) ,  strides=(2,2) ,  padding='same',dilation_rate = (1,1), use_bias=False, data_format=IMAGE_ORDERING, name=\"Transpose_pool2\" )(x))\n",
    "    print(x.shape)\n",
    "    #concatinate x and f1 for 5th Deconv layer\n",
    "    \n",
    "    x = concatenate ([x, f1],axis = 3)   \n",
    "    print(x.shape) \n",
    "    x = (Conv2DTranspose( nClasses + nClasses1 , kernel_size=(3,3) ,  strides=(2,2) , padding='same',dilation_rate = (1,1), use_bias=False, data_format=IMAGE_ORDERING, name=\"Transpose_pool1\" )(x))\n",
    "    print(x.shape)\n",
    "    o = x\n",
    "    o = (Activation('sigmoid', name=\"depth_out\"))(o)\n",
    "\n",
    "    # Block Transpose <DECODER> : Scale\n",
    "    #1st deconv layer 7x7\n",
    "    x2 = (Conv2DTranspose( 72, kernel_size=(4,4) ,  strides=(2,2) , padding='same', dilation_rate = (1,1), use_bias=False, data_format=IMAGE_ORDERING, name=\"Transpose_pool5_2\" ) (pool5))\n",
    "   \n",
    "    #concatinate x and pool4 for 2nd Deconv layer 14x14\n",
    "    x2 = concatenate ([x2, pool4],axis = 3)\n",
    "    print(x2.shape)\n",
    "    x2 = (Conv2DTranspose( 36 , kernel_size=(6,6) ,  strides=(2,2) ,padding='same', dilation_rate = (1,1), use_bias=False, data_format=IMAGE_ORDERING, name=\"Transpose_pool4_2\")(x2))\n",
    "    print(x2.shape)\n",
    "    #concatinate x and pool3 for 3rd Deconv layer 28x28\n",
    "    x2 = concatenate ([x2, pool3],axis = 3) \n",
    "    print(x2.shape)   \n",
    "    x2= (Conv2DTranspose( 18 , kernel_size=(4,4) ,  strides=(2,2) , padding='same',dilation_rate = (1,1), use_bias=False, data_format=IMAGE_ORDERING, name=\"Transpose_pool3_2\" )(x2))\n",
    "    print(x2.shape)\n",
    "    #concatinate x and f2 for 4th Deconv layer\n",
    "    x2 = concatenate ([x2, f2],axis = 3)   \n",
    "    print(x2.shape) \n",
    "    x2 = (Conv2DTranspose( 9 , kernel_size=(4,4) ,  strides=(2,2) ,  padding='same',dilation_rate = (1,1), use_bias=False, data_format=IMAGE_ORDERING, name=\"Transpose_pool2_2\" )(x2))\n",
    "    print(x2.shape)\n",
    "    #concatinate x and f1 for 5th Deconv layer\n",
    "    \n",
    "    x2 = concatenate ([x2, f1],axis = 3)  \n",
    "    print(x2.shape)  \n",
    "    x2 = (Conv2DTranspose( 7 , kernel_size=(3,3) ,  strides=(2,2) , padding='same',dilation_rate = (1,1), use_bias=False, data_format=IMAGE_ORDERING, name=\"Transpose_pool1_2\" )(x2))\n",
    "    print(x2.shape)\n",
    "    o2 = x2\n",
    "    o2 = (Activation('sigmoid', name=\"scale_out\"))(o2)\n",
    "\n",
    "    singleOut = concatenate([o,o2],axis = 3, name=\"single_out\")\n",
    "    print(singleOut.shape)\n",
    "    #model creation\n",
    "    model = Model(img_input, singleOut)\n",
    "       \n",
    "    return model\n",
    "input_height = 128\n",
    "input_width = 128\n",
    "nClasses = 10\n",
    "nClasses1 = 5\n",
    "input_tensor = np.random.rand(1, input_height, input_width, 6)\n",
    "print(input_tensor.shape)\n",
    "model = FluidNet(nClasses, nClasses1, input_height, input_width)\n",
    "\n",
    "# Get the output tensor\n",
    "output_tensor = model.output\n",
    "print(output_tensor.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
